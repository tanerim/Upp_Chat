# ğŸ§  LLM Duel â€“ Local Model Conversation Arena

LLM Duel is a **FastAPI web app** that lets two **locally hosted LLMs (via [Ollama](https://ollama.ai))** talk to each other in real time.  
You can define the **role and goal** of one model, then watch it start and sustain a conversation with another model through a **live, color-coded chat interface**.

---

## ğŸš€ Features

- **Dual Model Interface** â€“ Select any two local Ollama models for a back-and-forth â€œduelâ€.
- **System Prompt Mode** â€“ Define a *persona or goal* for the left model; it uses this as a system prompt to start the chat.
- **Live Streaming (SSE)** â€“ Messages appear token by token in real time using Server-Sent Events.
- **Visual Clarity**  
  - Left model = ğŸŸ¡ light yellow messages  
  - Right model = ğŸŸ¢ light green messages  
  - Each message block is labeled with the model name.
- **Custom Parameters** â€“ Set temperature, top-k, and top-p values per model.
- **Conversation Control** â€“ Stop or save any dialogue into a local SQLite database.

---

## ğŸ—ï¸ Project Structure

- ollama_duel/
- â”‚
- â”œâ”€â”€ main.py # FastAPI backend
- â”œâ”€â”€ db.py # SQLite setup and helpers
- â”œâ”€â”€ templates/
- â”‚ â””â”€â”€ index.html # Frontend interface
- â”œâ”€â”€ static/
- â”‚ â””â”€â”€ style.css # Styling for UI
- â””â”€â”€ requirements.txt # Dependencies


---

## âš™ï¸ Installation

1. **Clone or copy the repository**

   ```bash
   git clone https://github.com/yourusername/ollama_duel.git
   cd ollama_duel
   pip install fastapi uvicorn jinja2 ollama
   ```
2. **Make sure ollama is running**   
    ```bash
   ollama serve
   ollama list
   ```
3. ** RUn the app **
    ```bash
   uvicorn main:app --reload --port 8008
   ```


## How It Works

### Choose models
- Pick your left and right models from your installed Ollama list.

### Set model parameters
- You can set temperature, Top K and Top P parameters for each model.

### Define the left modelâ€™s role
- When prompted, describe the left modelâ€™s persona or mission, e.g.

        You are a philosopher debating ethics.

## Watch the conversation
- The left model starts the conversation using your role definition,
and the right model responds â€” all streamed live in the browser.

## Stop or save
- You can stop the dialogue anytime and save the conversation (with parameters and model names) to a local SQLite database.

## ğŸ› ï¸ TO_DO and  Ideas

- Add a â€œswap rolesâ€ button to reverse model order.
- Include a temperature sync toggle.
- Visualize conversation history in a separate page.
- Export saved conversations as Markdown or JSON.
